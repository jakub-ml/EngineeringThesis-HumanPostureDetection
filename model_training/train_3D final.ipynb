{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nessesery libraries and functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_time_sample(X_train_data, Y_train_data, sample_size, seed):\n",
    "#     return np.array([X_train_data[i:i+sample_size] for i in range(X_train_data.shape[0]-sample_size)]), np.array(Y_train_data[sample_size:])\n",
    "\n",
    "def train_model(X, Y, X_test, Y_test, model_type, epochs, sample_size, hidden_units, seed):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X = scaler.fit_transform(X)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    X, Y= np.array([X[i:i+sample_size] for i in range(X.shape[0]-sample_size)]), np.array(Y[sample_size:])\n",
    "    X_test, Y_test= np.array([X_test[i:i+sample_size] for i in range(X_test.shape[0]-sample_size)]), np.array(Y_test[sample_size:])\n",
    "\n",
    "    if model_type==\"RNN\":\n",
    "        model = Sequential([SimpleRNN(hidden_units, activation='softmax', input_shape=(sample_size, 99))])  # 5 klas wyjściowych\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    elif model_type==\"GRU\":\n",
    "        model = Sequential([GRU(hidden_units, activation='softmax', input_shape=(sample_size, 99))])  # 5 klas wyjściowych\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    elif model_type==\"LSTM\":\n",
    "        model = Sequential([LSTM(hidden_units, activation='softmax', input_shape=(sample_size, 99))])  # 5 klas wyjściowych\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    training_time=time.time()\n",
    "    history=model.fit(X, Y, validation_data=(X_test, Y_test), epochs=epochs)\n",
    "    training_time=time.time()-training_time\n",
    "    output_time=time.time()\n",
    "    example_n=10\n",
    "    for example in range(example_n):\n",
    "        model.predict(X_test[example].reshape(1,sample_size, 99))\n",
    "    output_time=(time.time()-output_time)/example_n\n",
    "    return history, training_time, output_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 49\u001b[0m\n\u001b[0;32m     45\u001b[0m         plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Call the function to visualize\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[43mplot_3d_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_data_0\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m15000\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m15100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[25], line 45\u001b[0m, in \u001b[0;36mplot_3d_frames\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     42\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_zlim(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Zakres dla osi Z\u001b[39;00m\n\u001b[0;32m     43\u001b[0m clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 45\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\matplotlib\\pyplot.py:353\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    352\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _backend_mod\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\matplotlib_inline\\backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m figure_manager \u001b[38;5;129;01min\u001b[39;00m Gcf\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[1;32m---> 90\u001b[0m         \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fetch_figure_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     show\u001b[38;5;241m.\u001b[39m_to_draw \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\IPython\\core\\display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\IPython\\core\\formatters.py:179\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    177\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\IPython\\core\\formatters.py:223\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 223\u001b[0m     r \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\IPython\\core\\formatters.py:340\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    342\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\IPython\\core\\pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[0;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[1;32m--> 152\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mprint_figure(bytes_io, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    153\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\matplotlib\\backend_bases.py:2193\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2189\u001b[0m ctx \u001b[38;5;241m=\u001b[39m (renderer\u001b[38;5;241m.\u001b[39m_draw_disabled()\n\u001b[0;32m   2190\u001b[0m        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(renderer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_draw_disabled\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2191\u001b[0m        \u001b[38;5;28;01melse\u001b[39;00m suppress())\n\u001b[0;32m   2192\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx:\n\u001b[1;32m-> 2193\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2195\u001b[0m bbox_inches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mget_tightbbox(\n\u001b[0;32m   2196\u001b[0m     renderer, bbox_extra_artists\u001b[38;5;241m=\u001b[39mbbox_extra_artists)\n\u001b[0;32m   2197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pad_inches \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\matplotlib\\artist.py:41\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\matplotlib\\figure.py:1863\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   1860\u001b[0m             \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1866\u001b[0m     renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\matplotlib\\image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 131\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\matplotlib\\artist.py:41\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\mpl_toolkits\\mplot3d\\axes3d.py:461\u001b[0m, in \u001b[0;36mAxes3D.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;66;03m# Then axes\u001b[39;00m\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_list():\n\u001b[1;32m--> 461\u001b[0m         \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;66;03m# Then rest\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\matplotlib\\artist.py:41\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\mpl_toolkits\\mplot3d\\axis3d.py:240\u001b[0m, in \u001b[0;36mAxis.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    237\u001b[0m edgep2 \u001b[38;5;241m=\u001b[39m edgep1\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    238\u001b[0m edgep2[juggled[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m maxmin[juggled[\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m    239\u001b[0m pep \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[1;32m--> 240\u001b[0m     \u001b[43mproj3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproj_trans_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43medgep1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medgep2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    241\u001b[0m centpt \u001b[38;5;241m=\u001b[39m proj3d\u001b[38;5;241m.\u001b[39mproj_transform(\u001b[38;5;241m*\u001b[39mcenters, renderer\u001b[38;5;241m.\u001b[39mM)\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline\u001b[38;5;241m.\u001b[39mset_data(pep[\u001b[38;5;241m0\u001b[39m], pep[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\mpl_toolkits\\mplot3d\\proj3d.py:166\u001b[0m, in \u001b[0;36mproj_trans_points\u001b[1;34m(points, M)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mproj_trans_points\u001b[39m(points, M):\n\u001b[0;32m    165\u001b[0m     xs, ys, zs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mpoints)\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mproj_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\mpl_toolkits\\mplot3d\\proj3d.py:144\u001b[0m, in \u001b[0;36mproj_transform\u001b[1;34m(xs, ys, zs, M)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03mTransform the points by the projection matrix\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    143\u001b[0m vec \u001b[38;5;241m=\u001b[39m _vec_pad_ones(xs, ys, zs)\n\u001b[1;32m--> 144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_proj_transform_vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\mpl_toolkits\\mplot3d\\proj3d.py:106\u001b[0m, in \u001b[0;36m_proj_transform_vec\u001b[1;34m(vec, M)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_proj_transform_vec\u001b[39m(vec, M):\n\u001b[1;32m--> 106\u001b[0m     vecw \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m     w \u001b[38;5;241m=\u001b[39m vecw[\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m# clip here..\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import clear_output\n",
    "\n",
    "X_train_data_0=pd.read_csv(\"data/big_dataset/data_3D/train/train_2.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "# X_train_data_0=pd.read_csv(\"data/small_dataset/data_3D/test/test.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "# data/small_dataset/data_3D/test/Main/\n",
    "# Simulate the provided data in a DataFrame format for simplicity\n",
    "columns = [f\"{axis}_{i}\" for i in range(33) for axis in ['X', 'Y', 'Z']]\n",
    "\n",
    "\n",
    "# Function to visualize the 3D scatter plot for each frame\n",
    "def plot_3d_frames(data):\n",
    "    num_frames = data.shape[0]  # Number of rows (frames)\n",
    "    num_points = 33  # Number of points per frame (X, Y, Z for each point)\n",
    "    \n",
    "    \n",
    "    for frame in range(num_frames):\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "        ax.clear()\n",
    "        ax.set_title(f\"Frame {frame + 1}\")\n",
    "        ax.set_xlabel('X-axis')\n",
    "        ax.set_ylabel('Y-axis')\n",
    "        ax.set_zlabel('Z-axis')\n",
    "        ax.set_xlim(-10, 50)\n",
    "        ax.set_ylim(-10, 50)\n",
    "        ax.set_zlim(-10, 50)\n",
    "        \n",
    "        # Extract coordinates for the current frame\n",
    "        x = data.iloc[frame, 0::3].values\n",
    "        y = data.iloc[frame, 1::3].values\n",
    "        z = data.iloc[frame, 2::3].values\n",
    "        \n",
    "        ax.scatter(x, y, z, c='blue', marker='o')\n",
    "        # plt.pause(0.5)  # Pause to create an animation effect\n",
    "        print(\"z\")\n",
    "        ax.set_xlim(0, 2)  # Zakres dla osi X\n",
    "        ax.set_ylim(0, 2)  # Zakres dla osi Y\n",
    "        ax.set_zlim(0, 2)  # Zakres dla osi Z\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Call the function to visualize\n",
    "plot_3d_frames(X_train_data_0[15000:15100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_0</th>\n",
       "      <th>Y_0</th>\n",
       "      <th>Z_0</th>\n",
       "      <th>X_1</th>\n",
       "      <th>Y_1</th>\n",
       "      <th>Z_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>Y_2</th>\n",
       "      <th>Z_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Z_29</th>\n",
       "      <th>X_30</th>\n",
       "      <th>Y_30</th>\n",
       "      <th>Z_30</th>\n",
       "      <th>X_31</th>\n",
       "      <th>Y_31</th>\n",
       "      <th>Z_31</th>\n",
       "      <th>X_32</th>\n",
       "      <th>Y_32</th>\n",
       "      <th>Z_32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.828839</td>\n",
       "      <td>0.423392</td>\n",
       "      <td>0.415314</td>\n",
       "      <td>3.233280</td>\n",
       "      <td>0.515086</td>\n",
       "      <td>0.279445</td>\n",
       "      <td>3.382928</td>\n",
       "      <td>0.548685</td>\n",
       "      <td>0.230653</td>\n",
       "      <td>3.543431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.719133</td>\n",
       "      <td>1.741720</td>\n",
       "      <td>0.205445</td>\n",
       "      <td>0.740747</td>\n",
       "      <td>1.511687</td>\n",
       "      <td>0.103929</td>\n",
       "      <td>0.696268</td>\n",
       "      <td>1.845736</td>\n",
       "      <td>0.155022</td>\n",
       "      <td>0.681697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.381691</td>\n",
       "      <td>0.097386</td>\n",
       "      <td>0.866872</td>\n",
       "      <td>1.377327</td>\n",
       "      <td>0.095385</td>\n",
       "      <td>0.872432</td>\n",
       "      <td>1.375127</td>\n",
       "      <td>0.093936</td>\n",
       "      <td>0.873326</td>\n",
       "      <td>1.374142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673280</td>\n",
       "      <td>1.591470</td>\n",
       "      <td>0.135298</td>\n",
       "      <td>0.674425</td>\n",
       "      <td>1.434330</td>\n",
       "      <td>0.078734</td>\n",
       "      <td>0.674250</td>\n",
       "      <td>1.570873</td>\n",
       "      <td>0.132920</td>\n",
       "      <td>0.682585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.304942</td>\n",
       "      <td>0.084829</td>\n",
       "      <td>0.885109</td>\n",
       "      <td>1.299574</td>\n",
       "      <td>0.082430</td>\n",
       "      <td>0.891857</td>\n",
       "      <td>1.293062</td>\n",
       "      <td>0.079867</td>\n",
       "      <td>0.894292</td>\n",
       "      <td>1.288177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796927</td>\n",
       "      <td>2.348281</td>\n",
       "      <td>0.303343</td>\n",
       "      <td>0.772202</td>\n",
       "      <td>0.266334</td>\n",
       "      <td>-0.197001</td>\n",
       "      <td>0.571566</td>\n",
       "      <td>1.103173</td>\n",
       "      <td>0.045387</td>\n",
       "      <td>0.666031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.295548</td>\n",
       "      <td>0.098427</td>\n",
       "      <td>0.881159</td>\n",
       "      <td>1.293603</td>\n",
       "      <td>0.097135</td>\n",
       "      <td>0.886935</td>\n",
       "      <td>1.289219</td>\n",
       "      <td>0.095386</td>\n",
       "      <td>0.888658</td>\n",
       "      <td>1.284589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633161</td>\n",
       "      <td>1.205666</td>\n",
       "      <td>0.053165</td>\n",
       "      <td>0.653815</td>\n",
       "      <td>1.084993</td>\n",
       "      <td>0.010385</td>\n",
       "      <td>0.640754</td>\n",
       "      <td>1.195926</td>\n",
       "      <td>0.073491</td>\n",
       "      <td>0.667534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.233472</td>\n",
       "      <td>0.105397</td>\n",
       "      <td>0.894467</td>\n",
       "      <td>1.229241</td>\n",
       "      <td>0.103987</td>\n",
       "      <td>0.901779</td>\n",
       "      <td>1.219025</td>\n",
       "      <td>0.101584</td>\n",
       "      <td>0.905282</td>\n",
       "      <td>1.210588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.678169</td>\n",
       "      <td>1.101435</td>\n",
       "      <td>0.042771</td>\n",
       "      <td>0.648668</td>\n",
       "      <td>1.274713</td>\n",
       "      <td>0.081070</td>\n",
       "      <td>0.683361</td>\n",
       "      <td>1.152987</td>\n",
       "      <td>0.076003</td>\n",
       "      <td>0.664949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4766</th>\n",
       "      <td>2.317302</td>\n",
       "      <td>0.309504</td>\n",
       "      <td>0.643538</td>\n",
       "      <td>2.313569</td>\n",
       "      <td>0.307280</td>\n",
       "      <td>0.643267</td>\n",
       "      <td>2.316313</td>\n",
       "      <td>0.306923</td>\n",
       "      <td>0.642431</td>\n",
       "      <td>2.320777</td>\n",
       "      <td>...</td>\n",
       "      <td>1.060804</td>\n",
       "      <td>3.341572</td>\n",
       "      <td>0.547258</td>\n",
       "      <td>1.055337</td>\n",
       "      <td>2.700192</td>\n",
       "      <td>0.371493</td>\n",
       "      <td>0.943436</td>\n",
       "      <td>2.822642</td>\n",
       "      <td>0.424563</td>\n",
       "      <td>0.981415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4767</th>\n",
       "      <td>1.581848</td>\n",
       "      <td>0.137443</td>\n",
       "      <td>0.806834</td>\n",
       "      <td>1.585438</td>\n",
       "      <td>0.139748</td>\n",
       "      <td>0.809331</td>\n",
       "      <td>1.585699</td>\n",
       "      <td>0.140636</td>\n",
       "      <td>0.809379</td>\n",
       "      <td>1.585758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660654</td>\n",
       "      <td>1.486057</td>\n",
       "      <td>0.111432</td>\n",
       "      <td>0.658573</td>\n",
       "      <td>1.472528</td>\n",
       "      <td>0.120384</td>\n",
       "      <td>0.647124</td>\n",
       "      <td>1.511167</td>\n",
       "      <td>0.118216</td>\n",
       "      <td>0.649486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4768</th>\n",
       "      <td>1.542999</td>\n",
       "      <td>0.132477</td>\n",
       "      <td>0.816417</td>\n",
       "      <td>1.544777</td>\n",
       "      <td>0.134457</td>\n",
       "      <td>0.819477</td>\n",
       "      <td>1.544370</td>\n",
       "      <td>0.135407</td>\n",
       "      <td>0.819678</td>\n",
       "      <td>1.544015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.650224</td>\n",
       "      <td>1.446323</td>\n",
       "      <td>0.104081</td>\n",
       "      <td>0.657922</td>\n",
       "      <td>1.428872</td>\n",
       "      <td>0.116722</td>\n",
       "      <td>0.645561</td>\n",
       "      <td>1.464923</td>\n",
       "      <td>0.108703</td>\n",
       "      <td>0.649595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4769</th>\n",
       "      <td>1.497666</td>\n",
       "      <td>0.126031</td>\n",
       "      <td>0.828038</td>\n",
       "      <td>1.500766</td>\n",
       "      <td>0.128275</td>\n",
       "      <td>0.831251</td>\n",
       "      <td>1.499311</td>\n",
       "      <td>0.129216</td>\n",
       "      <td>0.831841</td>\n",
       "      <td>1.497928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674566</td>\n",
       "      <td>1.441490</td>\n",
       "      <td>0.107233</td>\n",
       "      <td>0.673190</td>\n",
       "      <td>1.388296</td>\n",
       "      <td>0.107508</td>\n",
       "      <td>0.662384</td>\n",
       "      <td>1.443153</td>\n",
       "      <td>0.104456</td>\n",
       "      <td>0.666870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4770</th>\n",
       "      <td>1.472798</td>\n",
       "      <td>0.123818</td>\n",
       "      <td>0.834851</td>\n",
       "      <td>1.474418</td>\n",
       "      <td>0.125982</td>\n",
       "      <td>0.838774</td>\n",
       "      <td>1.474696</td>\n",
       "      <td>0.127101</td>\n",
       "      <td>0.838865</td>\n",
       "      <td>1.474011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660205</td>\n",
       "      <td>1.387398</td>\n",
       "      <td>0.098123</td>\n",
       "      <td>0.660119</td>\n",
       "      <td>1.377535</td>\n",
       "      <td>0.111494</td>\n",
       "      <td>0.655034</td>\n",
       "      <td>1.417141</td>\n",
       "      <td>0.102277</td>\n",
       "      <td>0.657055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4771 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X_0       Y_0       Z_0       X_1       Y_1       Z_1       X_2  \\\n",
       "0     2.828839  0.423392  0.415314  3.233280  0.515086  0.279445  3.382928   \n",
       "1     1.381691  0.097386  0.866872  1.377327  0.095385  0.872432  1.375127   \n",
       "2     1.304942  0.084829  0.885109  1.299574  0.082430  0.891857  1.293062   \n",
       "3     1.295548  0.098427  0.881159  1.293603  0.097135  0.886935  1.289219   \n",
       "4     1.233472  0.105397  0.894467  1.229241  0.103987  0.901779  1.219025   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4766  2.317302  0.309504  0.643538  2.313569  0.307280  0.643267  2.316313   \n",
       "4767  1.581848  0.137443  0.806834  1.585438  0.139748  0.809331  1.585699   \n",
       "4768  1.542999  0.132477  0.816417  1.544777  0.134457  0.819477  1.544370   \n",
       "4769  1.497666  0.126031  0.828038  1.500766  0.128275  0.831251  1.499311   \n",
       "4770  1.472798  0.123818  0.834851  1.474418  0.125982  0.838774  1.474696   \n",
       "\n",
       "           Y_2       Z_2       X_3  ...      Z_29      X_30      Y_30  \\\n",
       "0     0.548685  0.230653  3.543431  ...  0.719133  1.741720  0.205445   \n",
       "1     0.093936  0.873326  1.374142  ...  0.673280  1.591470  0.135298   \n",
       "2     0.079867  0.894292  1.288177  ...  0.796927  2.348281  0.303343   \n",
       "3     0.095386  0.888658  1.284589  ...  0.633161  1.205666  0.053165   \n",
       "4     0.101584  0.905282  1.210588  ...  0.678169  1.101435  0.042771   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4766  0.306923  0.642431  2.320777  ...  1.060804  3.341572  0.547258   \n",
       "4767  0.140636  0.809379  1.585758  ...  0.660654  1.486057  0.111432   \n",
       "4768  0.135407  0.819678  1.544015  ...  0.650224  1.446323  0.104081   \n",
       "4769  0.129216  0.831841  1.497928  ...  0.674566  1.441490  0.107233   \n",
       "4770  0.127101  0.838865  1.474011  ...  0.660205  1.387398  0.098123   \n",
       "\n",
       "          Z_30      X_31      Y_31      Z_31      X_32      Y_32      Z_32  \n",
       "0     0.740747  1.511687  0.103929  0.696268  1.845736  0.155022  0.681697  \n",
       "1     0.674425  1.434330  0.078734  0.674250  1.570873  0.132920  0.682585  \n",
       "2     0.772202  0.266334 -0.197001  0.571566  1.103173  0.045387  0.666031  \n",
       "3     0.653815  1.084993  0.010385  0.640754  1.195926  0.073491  0.667534  \n",
       "4     0.648668  1.274713  0.081070  0.683361  1.152987  0.076003  0.664949  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4766  1.055337  2.700192  0.371493  0.943436  2.822642  0.424563  0.981415  \n",
       "4767  0.658573  1.472528  0.120384  0.647124  1.511167  0.118216  0.649486  \n",
       "4768  0.657922  1.428872  0.116722  0.645561  1.464923  0.108703  0.649595  \n",
       "4769  0.673190  1.388296  0.107508  0.662384  1.443153  0.104456  0.666870  \n",
       "4770  0.660119  1.377535  0.111494  0.655034  1.417141  0.102277  0.657055  \n",
       "\n",
       "[4771 rows x 99 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([2.82883853, 3.23327978, 3.38292825, 3.54343084, 2.93684161,\n",
       "       2.90630661, 2.88708254, 3.86437224, 2.78735425, 3.07301175,\n",
       "       2.84687149, 8.08363729, 2.36095769, 2.54092619, 2.1666969 ,\n",
       "       1.62118433, 1.95248774, 1.61333875, 1.92216573, 1.61469203,\n",
       "       1.89706205, 1.61589158, 1.90457549, 1.95481545, 2.08648503,\n",
       "       1.6919258 , 1.9175492 , 1.59394256, 1.79114908, 1.59791161,\n",
       "       1.74171986, 1.51168675, 1.8457357 ])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_data_0=pd.read_csv(\"data/big_dataset/data_3D/train/train_0.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "display(X_train_data_0)\n",
    "x = X_train_data_0.iloc[0, 0::3].values\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data_0=pd.read_csv(\"data/big_dataset/data_3D/train/train_2.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "X_train_data_0=np.array(X_train_data_0)[2500:13040]\n",
    "\n",
    "X_train_data_1=pd.read_csv(\"data/big_dataset/data_3D/train/train_1.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "X_train_data_1=np.array(X_train_data_1)[2500:10250]\n",
    "\n",
    "X_train_data=np.concatenate((X_train_data_0, X_train_data_1), axis=0, out=None, dtype=None)\n",
    "\n",
    "X_test_data_0=pd.read_csv(\"data/big_dataset/data_3D/train/train_2.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "X_test_data_0=np.array(X_test_data_0)[:2500]\n",
    "\n",
    "X_test_data_1=pd.read_csv(\"data/big_dataset/data_3D/train/train_1.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "X_test_data_1=np.array(X_test_data_1)[:2500]\n",
    "\n",
    "X_test_data=np.concatenate((X_test_data_0, X_test_data_1), axis=0, out=None, dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_data_1\n",
    "len(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18290\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_data))\n",
    "# print(len(Y_train_data_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cat in categories:\n",
    "#     with open(file_path+cat+\".txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "#         content = file.read() \n",
    "    # print(len(content.split(\"\\n\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "file_path = \"data/big_dataset/data_3D/train/Main_2/\"\n",
    "categories=[\"inne\", \"odkładanie kartonu\", \"pakowanie\", \"rozpakowywanie\", \"sięganie po karton\"]\n",
    "Y_train_data_0=[None for e in range(X_train_data_0.shape[0])]\n",
    "for cat in categories:\n",
    "    with open(file_path+cat+\".txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read() \n",
    "    for id, example in enumerate(content.split(\"\\n\")[2500:13040]):\n",
    "\n",
    "        if example[-2:]==\" 1\":\n",
    "            Y_train_data_0[id]=categories.index(cat)\n",
    "\n",
    "file_path = \"data/big_dataset/data_3D/train/Main_1/\"\n",
    "categories=[\"inne\", \"odkładanie kartonu\", \"pakowanie\", \"rozpakowywanie\", \"sięganie po karton\"]\n",
    "Y_train_data_1=[None for e in range(X_train_data_1.shape[0])]\n",
    "for cat in categories:\n",
    "    with open(file_path+cat+\".txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read() \n",
    "    for id, example in enumerate(content.split(\"\\n\")[2500:10250]):\n",
    "        if example[-2:]==\" 1\":\n",
    "            Y_train_data_1[id]=categories.index(cat)\n",
    "Y_train_data=np.concatenate((Y_train_data_0, Y_train_data_1), axis=0, out=None, dtype=None)\n",
    "\n",
    "#test\n",
    "file_path = \"data/big_dataset/data_3D/train/Main_2/\"\n",
    "categories=[\"inne\", \"odkładanie kartonu\", \"pakowanie\", \"rozpakowywanie\", \"sięganie po karton\"]\n",
    "Y_test_data_0=[None for e in range(X_test_data_0.shape[0])]\n",
    "for cat in categories:\n",
    "    with open(file_path+cat+\".txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read() \n",
    "    for id, example in enumerate(content.split(\"\\n\")[:2500]):\n",
    "        if example[-2:]==\" 1\":\n",
    "            Y_test_data_0[id]=categories.index(cat)\n",
    "\n",
    "file_path = \"data/big_dataset/data_3D/train/Main_1/\"\n",
    "categories=[\"inne\", \"odkładanie kartonu\", \"pakowanie\", \"rozpakowywanie\", \"sięganie po karton\"]\n",
    "Y_test_data_1=[None for e in range(X_test_data_1.shape[0])]\n",
    "for cat in categories:\n",
    "    with open(file_path+cat+\".txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read() \n",
    "    for id, example in enumerate(content.split(\"\\n\")[:2500]):\n",
    "        if example[-2:]==\" 1\":\n",
    "            Y_test_data_1[id]=categories.index(cat)\n",
    "Y_test_data=np.concatenate((Y_test_data_0, Y_test_data_1), axis=0, out=None, dtype=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18290\n",
      "5000\n",
      "18290\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_data))\n",
    "print(len(X_test_data))\n",
    "print(len(Y_train_data))\n",
    "print(len(Y_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mY_test_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# len(Y_train_data_0)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "Y_test_data.index(None)\n",
    "# len(Y_train_data_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "[0.33372366428375244, 0.3852458894252777, 0.4156908690929413, 0.43325525522232056, 0.4250585436820984, 0.4291568994522095, 0.4303278625011444, 0.432084321975708, 0.43735364079475403, 0.4420374631881714, 0.4396955370903015, 0.44262295961380005, 0.443793922662735, 0.4508196711540222, 0.4531615972518921, 0.4525761008262634, 0.4590163826942444, 0.4590163826942444, 0.4625292718410492, 0.466042160987854, 0.46896955370903015, 0.47072598338127136, 0.47423887252807617, 0.48067915439605713, 0.477751761674881, 0.477751761674881, 0.48009368777275085, 0.48770493268966675, 0.483021080493927, 0.4871194362640381, 0.4865339696407318, 0.488290399312973, 0.4888758659362793, 0.49004682898521423, 0.488290399312973, 0.49004682898521423, 0.488290399312973, 0.4871194362640381, 0.48770493268966675, 0.4865339696407318, 0.48770493268966675, 0.49004682898521423, 0.4871194362640381, 0.48946136236190796, 0.49004682898521423, 0.4888758659362793, 0.4888758659362793, 0.48770493268966675, 0.4906323254108429, 0.4888758659362793, 0.48419204354286194, 0.4865339696407318, 0.4865339696407318, 0.4847775101661682, 0.4871194362640381, 0.48419204354286194, 0.48419204354286194, 0.48243558406829834, 0.4836065471172333, 0.48185011744499207, 0.4853630065917969, 0.4847775101661682, 0.48594847321510315, 0.48594847321510315, 0.48419204354286194, 0.48594847321510315, 0.48594847321510315, 0.488290399312973, 0.4853630065917969, 0.48594847321510315, 0.48770493268966675, 0.4853630065917969, 0.48946136236190796, 0.488290399312973, 0.48946136236190796, 0.4871194362640381, 0.48594847321510315, 0.4871194362640381, 0.4853630065917969, 0.48594847321510315, 0.4871194362640381, 0.4836065471172333, 0.4795081913471222, 0.4795081913471222, 0.48594847321510315, 0.48419204354286194, 0.483021080493927, 0.483021080493927, 0.48009368777275085, 0.48009368777275085, 0.4812646508216858, 0.483021080493927, 0.4847775101661682, 0.48185011744499207, 0.48009368777275085, 0.4812646508216858, 0.48243558406829834, 0.483021080493927, 0.48594847321510315, 0.48419204354286194]\n",
      "0.4906323254108429\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "path=\"data/small_dataset/data_3D/train_history/model_type_GRU hidden_units_32 sample_size_3.json\"\n",
    "with open(path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "l=data['val_accuracy']\n",
    "max_val=max(l)\n",
    "print(l.index(max_val))\n",
    "print(l)\n",
    "print(l[l.index(max_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 12/100\n",
    "468/468 [==============================] - 98s 210ms/step - loss: 0.6334 - accuracy: 0.7526 - val_loss: 0.7063 - val_accuracy: 0.7169\n",
    "Epoch 13/100\n",
    "468/468 [==============================] - 99s 212ms/step - loss: 0.6069 - accuracy: 0.7648 - val_loss: 0.6704 - val_accuracy: 0.7377\n",
    "Epoch 14/100\n",
    "468/468 [==============================] - 97s 208ms/step - loss: 0.5776 - accuracy: 0.7799 - val_loss: 0.6416 - val_accuracy: 0.7415\n",
    "Epoch 15/100\n",
    "468/468 [==============================] - 100s 214ms/step - loss: 0.5503 - accuracy: 0.7947 - val_loss: 0.6242 - val_accuracy: 0.7508\n",
    "Epoch 16/100\n",
    "468/468 [==============================] - 93s 198ms/step - loss: 0.5233 - accuracy: 0.8082 - val_loss: 0.5954 - val_accuracy: 0.7683\n",
    "Epoch 17/100\n",
    "468/468 [==============================] - 80s 170ms/step - loss: 0.4988 - accuracy: 0.8205 - val_loss: 0.5804 - val_accuracy: 0.7853\n",
    "Epoch 18/100\n",
    "468/468 [==============================] - 77s 165ms/step - loss: 0.4811 - accuracy: 0.8280 - val_loss: 0.5659 - val_accuracy: 0.7909\n",
    "Epoch 19/100\n",
    "468/468 [==============================] - 83s 177ms/step - loss: 0.4643 - accuracy: 0.8350 - val_loss: 0.5484 - val_accuracy: 0.7954\n",
    "Epoch 20/100\n",
    "468/468 [==============================] - 79s 168ms/step - loss: 0.4501 - accuracy: 0.8404 - val_loss: 0.5435 - val_accuracy: 0.8020\n",
    "Epoch 21/100\n",
    "468/468 [==============================] - 83s 176ms/step - loss: 0.4367 - accuracy: 0.8449 - val_loss: 0.5334 - val_accuracy: 0.8067\n",
    "Epoch 22/100\n",
    "468/468 [==============================] - 79s 169ms/step - loss: 0.4249 - accuracy: 0.8492 - val_loss: 0.5324 - val_accuracy: 0.8071\n",
    "Epoch 23/100\n",
    "468/468 [==============================] - 80s 172ms/step - loss: 0.4132 - accuracy: 0.8523 - val_loss: 0.5283 - val_accuracy: 0.8050\n",
    "Epoch 24/100\n",
    "468/468 [==============================] - 81s 173ms/step - loss: 0.4037 - accuracy: 0.8555 - val_loss: 0.5415 - val_accuracy: 0.8032\n",
    "Epoch 25/100\n",
    "468/468 [==============================] - 83s 178ms/step - loss: 0.3942 - accuracy: 0.8580 - val_loss: 0.5444 - val_accuracy: 0.8022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/100\n",
      "571/571 [==============================] - 133s 228ms/step - loss: 1.7587 - accuracy: 0.4484 - val_loss: 1.1616 - val_accuracy: 0.5562\n",
      "Epoch 2/100\n",
      "571/571 [==============================] - 149s 261ms/step - loss: 1.0583 - accuracy: 0.5910 - val_loss: 1.0032 - val_accuracy: 0.6046\n",
      "Epoch 3/100\n",
      "571/571 [==============================] - 145s 254ms/step - loss: 0.9451 - accuracy: 0.6242 - val_loss: 0.9348 - val_accuracy: 0.6181\n",
      "Epoch 4/100\n",
      "571/571 [==============================] - 177s 309ms/step - loss: 0.8771 - accuracy: 0.6482 - val_loss: 0.8939 - val_accuracy: 0.6266\n",
      "Epoch 5/100\n",
      "571/571 [==============================] - 145s 254ms/step - loss: 0.8240 - accuracy: 0.6633 - val_loss: 0.8579 - val_accuracy: 0.6339\n",
      "Epoch 6/100\n",
      "571/571 [==============================] - 125s 220ms/step - loss: 0.7801 - accuracy: 0.6840 - val_loss: 0.8226 - val_accuracy: 0.6560\n",
      "Epoch 7/100\n",
      "571/571 [==============================] - 158s 278ms/step - loss: 0.7373 - accuracy: 0.7062 - val_loss: 0.7995 - val_accuracy: 0.6702\n",
      "Epoch 8/100\n",
      "571/571 [==============================] - 158s 277ms/step - loss: 0.7010 - accuracy: 0.7228 - val_loss: 0.7692 - val_accuracy: 0.6829\n",
      "Epoch 9/100\n",
      "571/571 [==============================] - 134s 234ms/step - loss: 0.6668 - accuracy: 0.7420 - val_loss: 0.7419 - val_accuracy: 0.7065\n",
      "Epoch 10/100\n",
      "571/571 [==============================] - 168s 294ms/step - loss: 0.6316 - accuracy: 0.7597 - val_loss: 0.6991 - val_accuracy: 0.7218\n",
      "Epoch 11/100\n",
      "571/571 [==============================] - 145s 254ms/step - loss: 0.5961 - accuracy: 0.7766 - val_loss: 0.6848 - val_accuracy: 0.7359\n",
      "Epoch 12/100\n",
      "571/571 [==============================] - 138s 241ms/step - loss: 0.5659 - accuracy: 0.7887 - val_loss: 0.6551 - val_accuracy: 0.7446\n",
      "Epoch 13/100\n",
      "571/571 [==============================] - 116s 204ms/step - loss: 0.5404 - accuracy: 0.7981 - val_loss: 0.6509 - val_accuracy: 0.7478\n",
      "Epoch 14/100\n",
      "571/571 [==============================] - 146s 256ms/step - loss: 0.5206 - accuracy: 0.8060 - val_loss: 0.6283 - val_accuracy: 0.7599\n",
      "Epoch 15/100\n",
      "571/571 [==============================] - 154s 269ms/step - loss: 0.5019 - accuracy: 0.8153 - val_loss: 0.6081 - val_accuracy: 0.7688\n",
      "Epoch 16/100\n",
      "571/571 [==============================] - 164s 287ms/step - loss: 0.4852 - accuracy: 0.8227 - val_loss: 0.5901 - val_accuracy: 0.7776\n",
      "Epoch 17/100\n",
      "571/571 [==============================] - 167s 293ms/step - loss: 0.4701 - accuracy: 0.8266 - val_loss: 0.5743 - val_accuracy: 0.7855\n",
      "Epoch 18/100\n",
      "571/571 [==============================] - 156s 273ms/step - loss: 0.4571 - accuracy: 0.8323 - val_loss: 0.5630 - val_accuracy: 0.7881\n",
      "Epoch 19/100\n",
      "571/571 [==============================] - 154s 269ms/step - loss: 0.4447 - accuracy: 0.8358 - val_loss: 0.5540 - val_accuracy: 0.7978\n",
      "Epoch 20/100\n",
      "571/571 [==============================] - 149s 262ms/step - loss: 0.4321 - accuracy: 0.8425 - val_loss: 0.5513 - val_accuracy: 0.7968\n",
      "Epoch 21/100\n",
      "571/571 [==============================] - 155s 272ms/step - loss: 0.4221 - accuracy: 0.8436 - val_loss: 0.5381 - val_accuracy: 0.8006\n",
      "Epoch 22/100\n",
      "571/571 [==============================] - 150s 262ms/step - loss: 0.4131 - accuracy: 0.8487 - val_loss: 0.5221 - val_accuracy: 0.8123\n",
      "Epoch 23/100\n",
      "571/571 [==============================] - 160s 281ms/step - loss: 0.4043 - accuracy: 0.8515 - val_loss: 0.5338 - val_accuracy: 0.8026\n",
      "Epoch 24/100\n",
      "571/571 [==============================] - 132s 232ms/step - loss: 0.3985 - accuracy: 0.8533 - val_loss: 0.5302 - val_accuracy: 0.8069\n",
      "Epoch 25/100\n",
      "571/571 [==============================] - 144s 252ms/step - loss: 0.3908 - accuracy: 0.8567 - val_loss: 0.5172 - val_accuracy: 0.8192\n",
      "Epoch 26/100\n",
      "571/571 [==============================] - 158s 278ms/step - loss: 0.3851 - accuracy: 0.8585 - val_loss: 0.5170 - val_accuracy: 0.8177\n",
      "Epoch 27/100\n",
      "571/571 [==============================] - 164s 286ms/step - loss: 0.3797 - accuracy: 0.8602 - val_loss: 0.5173 - val_accuracy: 0.8208\n",
      "Epoch 28/100\n",
      "571/571 [==============================] - 159s 278ms/step - loss: 0.3724 - accuracy: 0.8639 - val_loss: 0.5103 - val_accuracy: 0.8234\n",
      "Epoch 29/100\n",
      "571/571 [==============================] - 169s 295ms/step - loss: 0.3726 - accuracy: 0.8620 - val_loss: 0.5046 - val_accuracy: 0.8232\n",
      "Epoch 30/100\n",
      "571/571 [==============================] - 176s 309ms/step - loss: 0.3633 - accuracy: 0.8677 - val_loss: 0.5048 - val_accuracy: 0.8214\n",
      "Epoch 31/100\n",
      "571/571 [==============================] - 184s 322ms/step - loss: 0.3582 - accuracy: 0.8699 - val_loss: 0.5097 - val_accuracy: 0.8238\n",
      "Epoch 32/100\n",
      "181/571 [========>.....................] - ETA: 1:17 - loss: 0.3552 - accuracy: 0.8717"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m sample_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# X, Y=create_time_sample(X_train_data, Y_train_data, sample_size, 42) #dodać normalizacje danych X\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# X_test, Y_test=create_time_sample(X_test_data, Y_test_data, sample_size, 42) #dodać normalizacje danych X\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m history, training_time, output_time \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_train_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_test_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGRU\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 28\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(X, Y, X_test, Y_test, model_type, epochs, sample_size, hidden_units, seed)\u001b[0m\n\u001b[0;32m     25\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     27\u001b[0m training_time\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 28\u001b[0m history\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m training_time\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mtraining_time\n\u001b[0;32m     30\u001b[0m output_time\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sample_size=40\n",
    "# X, Y=create_time_sample(X_train_data, Y_train_data, sample_size, 42) #dodać normalizacje danych X\n",
    "# X_test, Y_test=create_time_sample(X_test_data, Y_test_data, sample_size, 42) #dodać normalizacje danych X\n",
    "history, training_time, output_time = train_model(X=X_train_data, Y=Y_train_data, X_test=X_test_data, Y_test=Y_test_data, model_type=\"GRU\", epochs=100, sample_size=sample_size, hidden_units=32, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample size = 40, big\n",
    "Epoch 1/100\n",
    "468/468 [==============================] - 76s 160ms/step - loss: 1.8983 - accuracy: 0.4314 - val_loss: 1.2325 - val_accuracy: 0.5458\n",
    "Epoch 2/100\n",
    "468/468 [==============================] - 75s 160ms/step - loss: 1.1103 - accuracy: 0.5850 - val_loss: 1.0395 - val_accuracy: 0.6022\n",
    "Epoch 3/100\n",
    "468/468 [==============================] - 74s 159ms/step - loss: 0.9804 - accuracy: 0.6133 - val_loss: 0.9731 - val_accuracy: 0.6167\n",
    "Epoch 4/100\n",
    "468/468 [==============================] - 98s 209ms/step - loss: 0.9107 - accuracy: 0.6310 - val_loss: 0.9282 - val_accuracy: 0.6171\n",
    "Epoch 5/100\n",
    "468/468 [==============================] - 100s 214ms/step - loss: 0.8594 - accuracy: 0.6483 - val_loss: 0.8867 - val_accuracy: 0.6347\n",
    "Epoch 6/100\n",
    "468/468 [==============================] - 106s 226ms/step - loss: 0.8127 - accuracy: 0.6654 - val_loss: 0.8543 - val_accuracy: 0.6429\n",
    "Epoch 7/100\n",
    "468/468 [==============================] - 102s 218ms/step - loss: 0.7737 - accuracy: 0.6807 - val_loss: 0.8243 - val_accuracy: 0.6536\n",
    "Epoch 8/100\n",
    "468/468 [==============================] - 93s 199ms/step - loss: 0.7428 - accuracy: 0.6941 - val_loss: 0.8036 - val_accuracy: 0.6754\n",
    "Epoch 9/100\n",
    "468/468 [==============================] - 95s 202ms/step - loss: 0.7153 - accuracy: 0.7078 - val_loss: 0.7813 - val_accuracy: 0.6835\n",
    "Epoch 10/100\n",
    "468/468 [==============================] - 88s 188ms/step - loss: 0.6878 - accuracy: 0.7227 - val_loss: 0.7515 - val_accuracy: 0.7002\n",
    "Epoch 11/100\n",
    "468/468 [==============================] - 102s 219ms/step - loss: 0.6616 - accuracy: 0.7392 - val_loss: 0.7229 - val_accuracy: 0.7008\n",
    "Epoch 12/100\n",
    "468/468 [==============================] - 98s 210ms/step - loss: 0.6334 - accuracy: 0.7526 - val_loss: 0.7063 - val_accuracy: 0.7169\n",
    "Epoch 13/100\n",
    "468/468 [==============================] - 99s 212ms/step - loss: 0.6069 - accuracy: 0.7648 - val_loss: 0.6704 - val_accuracy: 0.7377\n",
    "Epoch 14/100\n",
    "468/468 [==============================] - 97s 208ms/step - loss: 0.5776 - accuracy: 0.7799 - val_loss: 0.6416 - val_accuracy: 0.7415\n",
    "Epoch 15/100\n",
    "468/468 [==============================] - 100s 214ms/step - loss: 0.5503 - accuracy: 0.7947 - val_loss: 0.6242 - val_accuracy: 0.7508\n",
    "Epoch 16/100\n",
    "468/468 [==============================] - 93s 198ms/step - loss: 0.5233 - accuracy: 0.8082 - val_loss: 0.5954 - val_accuracy: 0.7683\n",
    "Epoch 17/100\n",
    "468/468 [==============================] - 80s 170ms/step - loss: 0.4988 - accuracy: 0.8205 - val_loss: 0.5804 - val_accuracy: 0.7853\n",
    "Epoch 18/100\n",
    "468/468 [==============================] - 77s 165ms/step - loss: 0.4811 - accuracy: 0.8280 - val_loss: 0.5659 - val_accuracy: 0.7909\n",
    "Epoch 19/100\n",
    "468/468 [==============================] - 83s 177ms/step - loss: 0.4643 - accuracy: 0.8350 - val_loss: 0.5484 - val_accuracy: 0.7954\n",
    "Epoch 20/100\n",
    "468/468 [==============================] - 79s 168ms/step - loss: 0.4501 - accuracy: 0.8404 - val_loss: 0.5435 - val_accuracy: 0.8020\n",
    "Epoch 21/100\n",
    "468/468 [==============================] - 83s 176ms/step - loss: 0.4367 - accuracy: 0.8449 - val_loss: 0.5334 - val_accuracy: 0.8067\n",
    "Epoch 22/100\n",
    "468/468 [==============================] - 79s 169ms/step - loss: 0.4249 - accuracy: 0.8492 - val_loss: 0.5324 - val_accuracy: 0.8071\n",
    "Epoch 23/100\n",
    "468/468 [==============================] - 80s 172ms/step - loss: 0.4132 - accuracy: 0.8523 - val_loss: 0.5283 - val_accuracy: 0.8050\n",
    "Epoch 24/100\n",
    "468/468 [==============================] - 81s 173ms/step - loss: 0.4037 - accuracy: 0.8555 - val_loss: 0.5415 - val_accuracy: 0.8032\n",
    "Epoch 25/100\n",
    "468/468 [==============================] - 83s 178ms/step - loss: 0.3942 - accuracy: 0.8580 - val_loss: 0.5444 - val_accuracy: 0.8022\n",
    "Epoch 26/100\n",
    "468/468 [==============================] - 80s 170ms/step - loss: 0.3941 - accuracy: 0.8558 - val_loss: 0.5267 - val_accuracy: 0.8105\n",
    "Epoch 27/100\n",
    "468/468 [==============================] - 82s 176ms/step - loss: 0.3839 - accuracy: 0.8608 - val_loss: 0.5230 - val_accuracy: 0.8089\n",
    "Epoch 28/100\n",
    "468/468 [==============================] - 81s 174ms/step - loss: 0.3757 - accuracy: 0.8668 - val_loss: 0.5170 - val_accuracy: 0.8119\n",
    "Epoch 29/100\n",
    "468/468 [==============================] - 76s 162ms/step - loss: 0.3718 - accuracy: 0.8648 - val_loss: 0.5122 - val_accuracy: 0.8159\n",
    "Epoch 30/100\n",
    "468/468 [==============================] - 78s 167ms/step - loss: 0.3696 - accuracy: 0.8656 - val_loss: 0.5151 - val_accuracy: 0.8177\n",
    "Epoch 31/100\n",
    "468/468 [==============================] - 78s 167ms/step - loss: 0.3608 - accuracy: 0.8689 - val_loss: 0.5036 - val_accuracy: 0.8181\n",
    "Epoch 32/100\n",
    "468/468 [==============================] - 81s 174ms/step - loss: 0.3561 - accuracy: 0.8715 - val_loss: 0.5271 - val_accuracy: 0.8117\n",
    "Epoch 33/100\n",
    "468/468 [==============================] - 82s 176ms/step - loss: 0.3525 - accuracy: 0.8723 - val_loss: 0.5172 - val_accuracy: 0.8220\n",
    "Epoch 34/100\n",
    "468/468 [==============================] - 81s 172ms/step - loss: 0.3483 - accuracy: 0.8733 - val_loss: 0.5202 - val_accuracy: 0.8147\n",
    "Epoch 35/100\n",
    "468/468 [==============================] - 82s 175ms/step - loss: 0.3488 - accuracy: 0.8740 - val_loss: 0.4851 - val_accuracy: 0.8298\n",
    "Epoch 36/100\n",
    "468/468 [==============================] - 81s 173ms/step - loss: 0.3441 - accuracy: 0.8765 - val_loss: 0.4879 - val_accuracy: 0.8230\n",
    "Epoch 37/100\n",
    "468/468 [==============================] - 82s 175ms/step - loss: 0.3370 - accuracy: 0.8792 - val_loss: 0.5307 - val_accuracy: 0.8125\n",
    "Epoch 38/100\n",
    "468/468 [==============================] - 82s 174ms/step - loss: 0.3355 - accuracy: 0.8794 - val_loss: 0.4915 - val_accuracy: 0.8252\n",
    "Epoch 39/100\n",
    "468/468 [==============================] - 86s 183ms/step - loss: 0.3312 - accuracy: 0.8799 - val_loss: 0.4728 - val_accuracy: 0.8341\n",
    "Epoch 40/100\n",
    "468/468 [==============================] - 85s 181ms/step - loss: 0.3255 - accuracy: 0.8816 - val_loss: 0.4672 - val_accuracy: 0.8385\n",
    "Epoch 41/100\n",
    "468/468 [==============================] - 81s 172ms/step - loss: 0.3244 - accuracy: 0.8834 - val_loss: 0.4677 - val_accuracy: 0.8371\n",
    "Epoch 42/100\n",
    "468/468 [==============================] - 83s 176ms/step - loss: 0.3245 - accuracy: 0.8831 - val_loss: 0.4785 - val_accuracy: 0.8323\n",
    "Epoch 43/100\n",
    "468/468 [==============================] - 83s 177ms/step - loss: 0.3173 - accuracy: 0.8860 - val_loss: 0.4723 - val_accuracy: 0.8331\n",
    "Epoch 44/100\n",
    "468/468 [==============================] - 81s 174ms/step - loss: 0.3310 - accuracy: 0.8801 - val_loss: 0.4496 - val_accuracy: 0.8417\n",
    "Epoch 45/100\n",
    "468/468 [==============================] - 81s 172ms/step - loss: 0.3159 - accuracy: 0.8869 - val_loss: 0.4458 - val_accuracy: 0.8464\n",
    "Epoch 46/100\n",
    "468/468 [==============================] - 84s 179ms/step - loss: 0.3121 - accuracy: 0.8892 - val_loss: 0.4685 - val_accuracy: 0.8343\n",
    "Epoch 47/100\n",
    "468/468 [==============================] - 102s 219ms/step - loss: 0.3073 - accuracy: 0.8896 - val_loss: 0.4585 - val_accuracy: 0.8377\n",
    "Epoch 48/100\n",
    "468/468 [==============================] - 102s 217ms/step - loss: 0.3073 - accuracy: 0.8892 - val_loss: 0.4522 - val_accuracy: 0.8413\n",
    "Epoch 49/100\n",
    "468/468 [==============================] - 97s 208ms/step - loss: 0.3103 - accuracy: 0.8873 - val_loss: 0.4470 - val_accuracy: 0.8407\n",
    "Epoch 50/100\n",
    "468/468 [==============================] - 84s 180ms/step - loss: 0.3017 - accuracy: 0.8910 - val_loss: 0.4403 - val_accuracy: 0.8468\n",
    "Epoch 51/100\n",
    "468/468 [==============================] - 76s 162ms/step - loss: 0.2984 - accuracy: 0.8926 - val_loss: 0.4470 - val_accuracy: 0.8361\n",
    "Epoch 52/100\n",
    "468/468 [==============================] - 77s 164ms/step - loss: 0.2976 - accuracy: 0.8927 - val_loss: 0.4363 - val_accuracy: 0.8474\n",
    "Epoch 53/100\n",
    "468/468 [==============================] - 77s 165ms/step - loss: 0.2970 - accuracy: 0.8946 - val_loss: 0.4392 - val_accuracy: 0.8431\n",
    "Epoch 54/100\n",
    "468/468 [==============================] - 78s 166ms/step - loss: 0.2948 - accuracy: 0.8959 - val_loss: 0.4287 - val_accuracy: 0.8504\n",
    "Epoch 55/100\n",
    "468/468 [==============================] - 78s 168ms/step - loss: 0.2901 - accuracy: 0.8973 - val_loss: 0.4457 - val_accuracy: 0.8401\n",
    "Epoch 56/100\n",
    "468/468 [==============================] - 79s 169ms/step - loss: 0.2878 - accuracy: 0.8980 - val_loss: 0.4285 - val_accuracy: 0.8462\n",
    "Epoch 57/100\n",
    "468/468 [==============================] - 78s 167ms/step - loss: 0.2858 - accuracy: 0.8981 - val_loss: 0.4322 - val_accuracy: 0.8452\n",
    "Epoch 58/100\n",
    "468/468 [==============================] - 79s 168ms/step - loss: 0.2866 - accuracy: 0.8973 - val_loss: 0.4446 - val_accuracy: 0.8375\n",
    "Epoch 59/100\n",
    "468/468 [==============================] - 78s 167ms/step - loss: 0.2819 - accuracy: 0.8990 - val_loss: 0.4343 - val_accuracy: 0.8458\n",
    "Epoch 60/100\n",
    "468/468 [==============================] - 78s 166ms/step - loss: 0.2799 - accuracy: 0.9013 - val_loss: 0.4351 - val_accuracy: 0.8405\n",
    "Epoch 61/100\n",
    "468/468 [==============================] - 78s 167ms/step - loss: 0.2765 - accuracy: 0.9032 - val_loss: 0.4324 - val_accuracy: 0.8438\n",
    "Epoch 62/100\n",
    "468/468 [==============================] - 78s 166ms/step - loss: 0.2763 - accuracy: 0.9027 - val_loss: 0.4297 - val_accuracy: 0.8486\n",
    "Epoch 63/100\n",
    "468/468 [==============================] - 91s 194ms/step - loss: 0.2727 - accuracy: 0.9035 - val_loss: 0.4266 - val_accuracy: 0.8488\n",
    "Epoch 64/100\n",
    "468/468 [==============================] - 86s 184ms/step - loss: 0.2795 - accuracy: 0.9007 - val_loss: 0.4366 - val_accuracy: 0.8460\n",
    "Epoch 65/100\n",
    "468/468 [==============================] - 87s 186ms/step - loss: 0.2729 - accuracy: 0.9022 - val_loss: 0.4305 - val_accuracy: 0.8460\n",
    "Epoch 66/100\n",
    "468/468 [==============================] - 86s 185ms/step - loss: 0.2677 - accuracy: 0.9064 - val_loss: 0.4397 - val_accuracy: 0.8431\n",
    "Epoch 67/100\n",
    "468/468 [==============================] - 87s 186ms/step - loss: 0.2663 - accuracy: 0.9059 - val_loss: 0.4351 - val_accuracy: 0.8464\n",
    "Epoch 68/100\n",
    "468/468 [==============================] - 79s 170ms/step - loss: 0.2637 - accuracy: 0.9072 - val_loss: 0.4432 - val_accuracy: 0.8484\n",
    "Epoch 69/100\n",
    "468/468 [==============================] - 79s 168ms/step - loss: 0.2656 - accuracy: 0.9052 - val_loss: 0.4250 - val_accuracy: 0.8524\n",
    "Epoch 70/100\n",
    "468/468 [==============================] - 78s 167ms/step - loss: 0.2643 - accuracy: 0.9072 - val_loss: 0.4130 - val_accuracy: 0.8510\n",
    "Epoch 71/100\n",
    "468/468 [==============================] - 78s 166ms/step - loss: 0.2677 - accuracy: 0.9056 - val_loss: 0.4699 - val_accuracy: 0.8321\n",
    "Epoch 72/100\n",
    "468/468 [==============================] - 88s 188ms/step - loss: 0.2941 - accuracy: 0.8949 - val_loss: 0.4513 - val_accuracy: 0.8423\n",
    "Epoch 73/100\n",
    "468/468 [==============================] - 88s 189ms/step - loss: 0.2895 - accuracy: 0.8984 - val_loss: 0.4174 - val_accuracy: 0.8524\n",
    "Epoch 74/100\n",
    "468/468 [==============================] - 87s 186ms/step - loss: 0.2701 - accuracy: 0.9037 - val_loss: 0.4328 - val_accuracy: 0.8476\n",
    "Epoch 75/100\n",
    "468/468 [==============================] - 93s 198ms/step - loss: 0.2613 - accuracy: 0.9069 - val_loss: 0.4193 - val_accuracy: 0.8524\n",
    "Epoch 76/100\n",
    "468/468 [==============================] - 89s 189ms/step - loss: 0.2565 - accuracy: 0.9088 - val_loss: 0.4419 - val_accuracy: 0.8438\n",
    "Epoch 77/100\n",
    "468/468 [==============================] - 94s 201ms/step - loss: 0.2557 - accuracy: 0.9103 - val_loss: 0.4316 - val_accuracy: 0.8504\n",
    "Epoch 78/100\n",
    "468/468 [==============================] - 85s 181ms/step - loss: 0.2549 - accuracy: 0.9112 - val_loss: 0.4504 - val_accuracy: 0.8385\n",
    "Epoch 79/100\n",
    "468/468 [==============================] - 89s 191ms/step - loss: 0.2539 - accuracy: 0.9114 - val_loss: 0.4346 - val_accuracy: 0.8506\n",
    "Epoch 80/100\n",
    "468/468 [==============================] - 84s 179ms/step - loss: 0.2539 - accuracy: 0.9113 - val_loss: 0.4295 - val_accuracy: 0.8482\n",
    "Epoch 81/100\n",
    "468/468 [==============================] - 84s 180ms/step - loss: 0.2506 - accuracy: 0.9132 - val_loss: 0.4378 - val_accuracy: 0.8462\n",
    "Epoch 82/100\n",
    "468/468 [==============================] - 86s 184ms/step - loss: 0.2513 - accuracy: 0.9134 - val_loss: 0.4403 - val_accuracy: 0.8504\n",
    "Epoch 83/100\n",
    "468/468 [==============================] - 87s 186ms/step - loss: 0.2593 - accuracy: 0.9106 - val_loss: 0.4296 - val_accuracy: 0.8516\n",
    "Epoch 84/100\n",
    "468/468 [==============================] - 85s 182ms/step - loss: 0.2507 - accuracy: 0.9140 - val_loss: 0.4434 - val_accuracy: 0.8494\n",
    "Epoch 85/100\n",
    "468/468 [==============================] - 85s 181ms/step - loss: 0.2523 - accuracy: 0.9137 - val_loss: 0.4339 - val_accuracy: 0.8486\n",
    "Epoch 86/100\n",
    "468/468 [==============================] - 89s 191ms/step - loss: 0.2498 - accuracy: 0.9130 - val_loss: 0.4644 - val_accuracy: 0.8456\n",
    "Epoch 87/100\n",
    "468/468 [==============================] - 82s 174ms/step - loss: 0.2491 - accuracy: 0.9148 - val_loss: 0.4457 - val_accuracy: 0.8482\n",
    "Epoch 88/100\n",
    "468/468 [==============================] - 81s 172ms/step - loss: 0.2460 - accuracy: 0.9152 - val_loss: 0.4497 - val_accuracy: 0.8454\n",
    "Epoch 89/100\n",
    "468/468 [==============================] - 95s 202ms/step - loss: 0.2478 - accuracy: 0.9155 - val_loss: 0.4645 - val_accuracy: 0.8415\n",
    "Epoch 90/100\n",
    "468/468 [==============================] - 92s 197ms/step - loss: 0.2456 - accuracy: 0.9158 - val_loss: 0.4462 - val_accuracy: 0.8508\n",
    "Epoch 91/100\n",
    "468/468 [==============================] - 91s 195ms/step - loss: 0.2444 - accuracy: 0.9164 - val_loss: 0.4648 - val_accuracy: 0.8452\n",
    "Epoch 92/100\n",
    "468/468 [==============================] - 88s 188ms/step - loss: 0.2502 - accuracy: 0.9141 - val_loss: 0.4330 - val_accuracy: 0.8548\n",
    "Epoch 93/100\n",
    "468/468 [==============================] - 87s 187ms/step - loss: 0.2489 - accuracy: 0.9144 - val_loss: 0.4419 - val_accuracy: 0.8514\n",
    "Epoch 94/100\n",
    "468/468 [==============================] - 87s 187ms/step - loss: 0.2410 - accuracy: 0.9167 - val_loss: 0.4478 - val_accuracy: 0.8514\n",
    "Epoch 95/100\n",
    "468/468 [==============================] - 82s 176ms/step - loss: 0.2455 - accuracy: 0.9154 - val_loss: 0.4559 - val_accuracy: 0.8458\n",
    "Epoch 96/100\n",
    "468/468 [==============================] - 82s 176ms/step - loss: 0.2410 - accuracy: 0.9195 - val_loss: 0.4465 - val_accuracy: 0.8534\n",
    "Epoch 97/100\n",
    "468/468 [==============================] - 82s 176ms/step - loss: 0.2408 - accuracy: 0.9182 - val_loss: 0.4815 - val_accuracy: 0.8351\n",
    "Epoch 98/100\n",
    "468/468 [==============================] - 84s 180ms/step - loss: 0.2378 - accuracy: 0.9198 - val_loss: 0.4501 - val_accuracy: 0.8518\n",
    "Epoch 99/100\n",
    "468/468 [==============================] - 86s 184ms/step - loss: 0.2463 - accuracy: 0.9166 - val_loss: 0.5271 - val_accuracy: 0.8276\n",
    "Epoch 100/100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 3, big\n",
    "Epoch 1/100\n",
    "469/469 [==============================] - 11s 19ms/step - loss: 1.9247 - accuracy: 0.4141 - val_loss: 1.3302 - val_accuracy: 0.5073\n",
    "Epoch 2/100\n",
    "469/469 [==============================] - 11s 22ms/step - loss: 1.1855 - accuracy: 0.5244 - val_loss: 1.1044 - val_accuracy: 0.5503\n",
    "Epoch 3/100\n",
    "469/469 [==============================] - 14s 30ms/step - loss: 1.0592 - accuracy: 0.5480 - val_loss: 1.0371 - val_accuracy: 0.5681\n",
    "Epoch 4/100\n",
    "469/469 [==============================] - 19s 40ms/step - loss: 1.0017 - accuracy: 0.5650 - val_loss: 0.9869 - val_accuracy: 0.5795\n",
    "Epoch 5/100\n",
    "469/469 [==============================] - 19s 41ms/step - loss: 0.9606 - accuracy: 0.5820 - val_loss: 0.9555 - val_accuracy: 0.5954\n",
    "Epoch 6/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.9304 - accuracy: 0.5952 - val_loss: 0.9339 - val_accuracy: 0.6114\n",
    "Epoch 7/100\n",
    "469/469 [==============================] - 9s 20ms/step - loss: 0.9067 - accuracy: 0.6065 - val_loss: 0.9097 - val_accuracy: 0.6190\n",
    "Epoch 8/100\n",
    "469/469 [==============================] - 9s 20ms/step - loss: 0.8867 - accuracy: 0.6165 - val_loss: 0.8947 - val_accuracy: 0.6376\n",
    "Epoch 9/100\n",
    "469/469 [==============================] - 10s 21ms/step - loss: 0.8694 - accuracy: 0.6270 - val_loss: 0.8809 - val_accuracy: 0.6470\n",
    "Epoch 10/100\n",
    "469/469 [==============================] - 10s 21ms/step - loss: 0.8531 - accuracy: 0.6374 - val_loss: 0.8721 - val_accuracy: 0.6612\n",
    "Epoch 11/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.8390 - accuracy: 0.6503 - val_loss: 0.8556 - val_accuracy: 0.6632\n",
    "Epoch 12/100\n",
    "469/469 [==============================] - 13s 28ms/step - loss: 0.8252 - accuracy: 0.6566 - val_loss: 0.8480 - val_accuracy: 0.6622\n",
    "Epoch 13/100\n",
    "469/469 [==============================] - 11s 23ms/step - loss: 0.8140 - accuracy: 0.6645 - val_loss: 0.8380 - val_accuracy: 0.6702\n",
    "Epoch 14/100\n",
    "469/469 [==============================] - 10s 21ms/step - loss: 0.8020 - accuracy: 0.6684 - val_loss: 0.8280 - val_accuracy: 0.6784\n",
    "Epoch 15/100\n",
    "469/469 [==============================] - 13s 27ms/step - loss: 0.7897 - accuracy: 0.6769 - val_loss: 0.8158 - val_accuracy: 0.6856\n",
    "Epoch 16/100\n",
    "469/469 [==============================] - 10s 22ms/step - loss: 0.7771 - accuracy: 0.6820 - val_loss: 0.8109 - val_accuracy: 0.6858\n",
    "Epoch 17/100\n",
    "469/469 [==============================] - 11s 23ms/step - loss: 0.7653 - accuracy: 0.6866 - val_loss: 0.8004 - val_accuracy: 0.6878\n",
    "Epoch 18/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.7537 - accuracy: 0.6919 - val_loss: 0.7987 - val_accuracy: 0.6852\n",
    "Epoch 19/100\n",
    "469/469 [==============================] - 12s 25ms/step - loss: 0.7448 - accuracy: 0.6949 - val_loss: 0.7857 - val_accuracy: 0.6944\n",
    "Epoch 20/100\n",
    "469/469 [==============================] - 10s 22ms/step - loss: 0.7343 - accuracy: 0.6989 - val_loss: 0.7888 - val_accuracy: 0.6966\n",
    "Epoch 21/100\n",
    "469/469 [==============================] - 11s 24ms/step - loss: 0.7265 - accuracy: 0.7045 - val_loss: 0.7761 - val_accuracy: 0.6962\n",
    "Epoch 22/100\n",
    "469/469 [==============================] - 12s 25ms/step - loss: 0.7174 - accuracy: 0.7095 - val_loss: 0.7681 - val_accuracy: 0.7014\n",
    "Epoch 23/100\n",
    "469/469 [==============================] - 11s 24ms/step - loss: 0.7102 - accuracy: 0.7109 - val_loss: 0.7674 - val_accuracy: 0.6970\n",
    "Epoch 24/100\n",
    "469/469 [==============================] - 13s 27ms/step - loss: 0.7041 - accuracy: 0.7149 - val_loss: 0.7629 - val_accuracy: 0.6978\n",
    "Epoch 25/100\n",
    "469/469 [==============================] - 11s 23ms/step - loss: 0.6972 - accuracy: 0.7176 - val_loss: 0.7600 - val_accuracy: 0.7052\n",
    "Epoch 26/100\n",
    "469/469 [==============================] - 13s 27ms/step - loss: 0.6915 - accuracy: 0.7174 - val_loss: 0.7524 - val_accuracy: 0.7042\n",
    "Epoch 27/100\n",
    "469/469 [==============================] - 14s 30ms/step - loss: 0.6858 - accuracy: 0.7215 - val_loss: 0.7482 - val_accuracy: 0.7050\n",
    "Epoch 28/100\n",
    "469/469 [==============================] - 13s 28ms/step - loss: 0.6802 - accuracy: 0.7259 - val_loss: 0.7522 - val_accuracy: 0.7030\n",
    "Epoch 29/100\n",
    "469/469 [==============================] - 11s 23ms/step - loss: 0.6754 - accuracy: 0.7260 - val_loss: 0.7512 - val_accuracy: 0.7080\n",
    "Epoch 30/100\n",
    "469/469 [==============================] - 10s 22ms/step - loss: 0.6698 - accuracy: 0.7291 - val_loss: 0.7469 - val_accuracy: 0.7090\n",
    "Epoch 31/100\n",
    "469/469 [==============================] - 10s 21ms/step - loss: 0.6659 - accuracy: 0.7315 - val_loss: 0.7365 - val_accuracy: 0.7096\n",
    "Epoch 32/100\n",
    "469/469 [==============================] - 13s 28ms/step - loss: 0.6604 - accuracy: 0.7327 - val_loss: 0.7325 - val_accuracy: 0.7112\n",
    "Epoch 33/100\n",
    "469/469 [==============================] - 10s 22ms/step - loss: 0.6563 - accuracy: 0.7357 - val_loss: 0.7362 - val_accuracy: 0.7122\n",
    "Epoch 34/100\n",
    "469/469 [==============================] - 15s 32ms/step - loss: 0.6527 - accuracy: 0.7387 - val_loss: 0.7341 - val_accuracy: 0.7070\n",
    "Epoch 35/100\n",
    "469/469 [==============================] - 14s 29ms/step - loss: 0.6489 - accuracy: 0.7397 - val_loss: 0.7339 - val_accuracy: 0.7142\n",
    "Epoch 36/100\n",
    "469/469 [==============================] - 11s 23ms/step - loss: 0.6434 - accuracy: 0.7408 - val_loss: 0.7304 - val_accuracy: 0.7178\n",
    "Epoch 37/100\n",
    "469/469 [==============================] - 10s 22ms/step - loss: 0.6408 - accuracy: 0.7445 - val_loss: 0.7235 - val_accuracy: 0.7126\n",
    "Epoch 38/100\n",
    "469/469 [==============================] - 11s 23ms/step - loss: 0.6378 - accuracy: 0.7445 - val_loss: 0.7362 - val_accuracy: 0.7186\n",
    "Epoch 39/100\n",
    "469/469 [==============================] - 11s 24ms/step - loss: 0.6328 - accuracy: 0.7477 - val_loss: 0.7286 - val_accuracy: 0.7174\n",
    "Epoch 40/100\n",
    "469/469 [==============================] - 11s 24ms/step - loss: 0.6291 - accuracy: 0.7485 - val_loss: 0.7193 - val_accuracy: 0.7226\n",
    "Epoch 41/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.6268 - accuracy: 0.7526 - val_loss: 0.7161 - val_accuracy: 0.7218\n",
    "Epoch 42/100\n",
    "469/469 [==============================] - 14s 29ms/step - loss: 0.6233 - accuracy: 0.7513 - val_loss: 0.7176 - val_accuracy: 0.7238\n",
    "Epoch 43/100\n",
    "469/469 [==============================] - 18s 38ms/step - loss: 0.6209 - accuracy: 0.7530 - val_loss: 0.7267 - val_accuracy: 0.7212\n",
    "Epoch 44/100\n",
    "469/469 [==============================] - 16s 35ms/step - loss: 0.6172 - accuracy: 0.7558 - val_loss: 0.7154 - val_accuracy: 0.7214\n",
    "Epoch 45/100\n",
    "469/469 [==============================] - 16s 34ms/step - loss: 0.6139 - accuracy: 0.7562 - val_loss: 0.7180 - val_accuracy: 0.7264\n",
    "Epoch 46/100\n",
    "469/469 [==============================] - 15s 32ms/step - loss: 0.6106 - accuracy: 0.7576 - val_loss: 0.7196 - val_accuracy: 0.7298\n",
    "Epoch 47/100\n",
    "469/469 [==============================] - 11s 25ms/step - loss: 0.6079 - accuracy: 0.7593 - val_loss: 0.7040 - val_accuracy: 0.7284\n",
    "Epoch 48/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.6044 - accuracy: 0.7612 - val_loss: 0.7065 - val_accuracy: 0.7334\n",
    "Epoch 49/100\n",
    "469/469 [==============================] - 16s 34ms/step - loss: 0.6022 - accuracy: 0.7625 - val_loss: 0.7033 - val_accuracy: 0.7346\n",
    "Epoch 50/100\n",
    "469/469 [==============================] - 12s 25ms/step - loss: 0.6001 - accuracy: 0.7623 - val_loss: 0.7039 - val_accuracy: 0.7240\n",
    "Epoch 51/100\n",
    "469/469 [==============================] - 12s 25ms/step - loss: 0.5975 - accuracy: 0.7656 - val_loss: 0.7204 - val_accuracy: 0.7290\n",
    "Epoch 52/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.5954 - accuracy: 0.7664 - val_loss: 0.6960 - val_accuracy: 0.7348\n",
    "Epoch 53/100\n",
    "469/469 [==============================] - 12s 25ms/step - loss: 0.5941 - accuracy: 0.7650 - val_loss: 0.6998 - val_accuracy: 0.7312\n",
    "Epoch 54/100\n",
    "469/469 [==============================] - 12s 25ms/step - loss: 0.5895 - accuracy: 0.7688 - val_loss: 0.6985 - val_accuracy: 0.7362\n",
    "Epoch 55/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.5873 - accuracy: 0.7709 - val_loss: 0.6945 - val_accuracy: 0.7344\n",
    "Epoch 56/100\n",
    "469/469 [==============================] - 12s 25ms/step - loss: 0.5849 - accuracy: 0.7698 - val_loss: 0.6932 - val_accuracy: 0.7386\n",
    "Epoch 57/100\n",
    "469/469 [==============================] - 12s 25ms/step - loss: 0.5832 - accuracy: 0.7728 - val_loss: 0.6878 - val_accuracy: 0.7428\n",
    "Epoch 58/100\n",
    "469/469 [==============================] - 12s 25ms/step - loss: 0.5812 - accuracy: 0.7739 - val_loss: 0.6932 - val_accuracy: 0.7440\n",
    "Epoch 59/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.5804 - accuracy: 0.7718 - val_loss: 0.6925 - val_accuracy: 0.7408\n",
    "Epoch 60/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.5762 - accuracy: 0.7767 - val_loss: 0.6895 - val_accuracy: 0.7416\n",
    "Epoch 61/100\n",
    "469/469 [==============================] - 13s 27ms/step - loss: 0.5759 - accuracy: 0.7776 - val_loss: 0.6853 - val_accuracy: 0.7384\n",
    "Epoch 62/100\n",
    "469/469 [==============================] - 12s 25ms/step - loss: 0.5738 - accuracy: 0.7768 - val_loss: 0.6886 - val_accuracy: 0.7424\n",
    "Epoch 63/100\n",
    "469/469 [==============================] - 12s 25ms/step - loss: 0.5727 - accuracy: 0.7783 - val_loss: 0.6879 - val_accuracy: 0.7456\n",
    "Epoch 64/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.5681 - accuracy: 0.7812 - val_loss: 0.6898 - val_accuracy: 0.7446\n",
    "Epoch 65/100\n",
    "469/469 [==============================] - 13s 28ms/step - loss: 0.5664 - accuracy: 0.7829 - val_loss: 0.6849 - val_accuracy: 0.7460\n",
    "Epoch 66/100\n",
    "469/469 [==============================] - 12s 25ms/step - loss: 0.5656 - accuracy: 0.7812 - val_loss: 0.6852 - val_accuracy: 0.7424\n",
    "Epoch 67/100\n",
    "469/469 [==============================] - 13s 27ms/step - loss: 0.5628 - accuracy: 0.7828 - val_loss: 0.6863 - val_accuracy: 0.7501\n",
    "Epoch 68/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.5610 - accuracy: 0.7854 - val_loss: 0.6865 - val_accuracy: 0.7454\n",
    "Epoch 69/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.5596 - accuracy: 0.7858 - val_loss: 0.6851 - val_accuracy: 0.7446\n",
    "Epoch 70/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.5581 - accuracy: 0.7854 - val_loss: 0.6809 - val_accuracy: 0.7511\n",
    "Epoch 71/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.5560 - accuracy: 0.7848 - val_loss: 0.6849 - val_accuracy: 0.7428\n",
    "Epoch 72/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.5553 - accuracy: 0.7881 - val_loss: 0.6770 - val_accuracy: 0.7448\n",
    "Epoch 73/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.5525 - accuracy: 0.7874 - val_loss: 0.6785 - val_accuracy: 0.7519\n",
    "Epoch 74/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.5518 - accuracy: 0.7877 - val_loss: 0.6760 - val_accuracy: 0.7525\n",
    "Epoch 75/100\n",
    "469/469 [==============================] - 12s 25ms/step - loss: 0.5493 - accuracy: 0.7893 - val_loss: 0.6767 - val_accuracy: 0.7519\n",
    "Epoch 76/100\n",
    "469/469 [==============================] - 13s 27ms/step - loss: 0.5492 - accuracy: 0.7901 - val_loss: 0.6768 - val_accuracy: 0.7496\n",
    "Epoch 77/100\n",
    "469/469 [==============================] - 13s 27ms/step - loss: 0.5465 - accuracy: 0.7915 - val_loss: 0.6741 - val_accuracy: 0.7496\n",
    "Epoch 78/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.5458 - accuracy: 0.7894 - val_loss: 0.6731 - val_accuracy: 0.7537\n",
    "Epoch 79/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.5443 - accuracy: 0.7907 - val_loss: 0.6761 - val_accuracy: 0.7525\n",
    "Epoch 80/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.5413 - accuracy: 0.7928 - val_loss: 0.6797 - val_accuracy: 0.7541\n",
    "Epoch 81/100\n",
    "469/469 [==============================] - 13s 28ms/step - loss: 0.5412 - accuracy: 0.7918 - val_loss: 0.6811 - val_accuracy: 0.7492\n",
    "Epoch 82/100\n",
    "469/469 [==============================] - 13s 28ms/step - loss: 0.5391 - accuracy: 0.7942 - val_loss: 0.6718 - val_accuracy: 0.7527\n",
    "Epoch 83/100\n",
    "469/469 [==============================] - 12s 25ms/step - loss: 0.5366 - accuracy: 0.7951 - val_loss: 0.6774 - val_accuracy: 0.7561\n",
    "Epoch 84/100\n",
    "469/469 [==============================] - 13s 27ms/step - loss: 0.5358 - accuracy: 0.7949 - val_loss: 0.6706 - val_accuracy: 0.7557\n",
    "Epoch 85/100\n",
    "469/469 [==============================] - 12s 25ms/step - loss: 0.5360 - accuracy: 0.7940 - val_loss: 0.6773 - val_accuracy: 0.7476\n",
    "Epoch 86/100\n",
    "469/469 [==============================] - 12s 25ms/step - loss: 0.5335 - accuracy: 0.7942 - val_loss: 0.6677 - val_accuracy: 0.7561\n",
    "Epoch 87/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.5326 - accuracy: 0.7990 - val_loss: 0.6693 - val_accuracy: 0.7557\n",
    "Epoch 88/100\n",
    "469/469 [==============================] - 12s 25ms/step - loss: 0.5312 - accuracy: 0.7990 - val_loss: 0.6724 - val_accuracy: 0.7567\n",
    "Epoch 89/100\n",
    "469/469 [==============================] - 13s 27ms/step - loss: 0.5291 - accuracy: 0.7988 - val_loss: 0.6707 - val_accuracy: 0.7563\n",
    "Epoch 90/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.5291 - accuracy: 0.7982 - val_loss: 0.6617 - val_accuracy: 0.7533\n",
    "Epoch 91/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.5268 - accuracy: 0.8002 - val_loss: 0.6689 - val_accuracy: 0.7593\n",
    "Epoch 92/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.5262 - accuracy: 0.7993 - val_loss: 0.6709 - val_accuracy: 0.7547\n",
    "Epoch 93/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.5248 - accuracy: 0.8006 - val_loss: 0.6762 - val_accuracy: 0.7581\n",
    "Epoch 94/100\n",
    "469/469 [==============================] - 13s 27ms/step - loss: 0.5240 - accuracy: 0.8002 - val_loss: 0.6651 - val_accuracy: 0.7557\n",
    "Epoch 95/100\n",
    "469/469 [==============================] - 12s 25ms/step - loss: 0.5219 - accuracy: 0.8035 - val_loss: 0.6678 - val_accuracy: 0.7533\n",
    "Epoch 96/100\n",
    "469/469 [==============================] - 12s 25ms/step - loss: 0.5207 - accuracy: 0.8030 - val_loss: 0.6705 - val_accuracy: 0.7515\n",
    "Epoch 97/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.5197 - accuracy: 0.8048 - val_loss: 0.6686 - val_accuracy: 0.7462\n",
    "Epoch 98/100\n",
    "469/469 [==============================] - 13s 27ms/step - loss: 0.5190 - accuracy: 0.8043 - val_loss: 0.6719 - val_accuracy: 0.7549\n",
    "Epoch 99/100\n",
    "469/469 [==============================] - 12s 26ms/step - loss: 0.5180 - accuracy: 0.8022 - val_loss: 0.6673 - val_accuracy: 0.7577\n",
    "Epoch 100/100\n",
    "469/469 [==============================] - 13s 28ms/step - loss: 0.5160 - accuracy: 0.8052 - val_loss: 0.6731 - val_accuracy: 0.7543\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size=3 small\n",
    "Epoch 1/100\n",
    "157/157 [==============================] - 6s 22ms/step - loss: 2.4328 - accuracy: 0.3234 - val_loss: 1.8362 - val_accuracy: 0.4421\n",
    "Epoch 2/100\n",
    "157/157 [==============================] - 3s 20ms/step - loss: 1.5555 - accuracy: 0.4725 - val_loss: 1.3947 - val_accuracy: 0.5203\n",
    "Epoch 3/100\n",
    "157/157 [==============================] - 3s 19ms/step - loss: 1.2516 - accuracy: 0.5329 - val_loss: 1.2200 - val_accuracy: 0.5491\n",
    "Epoch 4/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 1.1151 - accuracy: 0.5593 - val_loss: 1.1267 - val_accuracy: 0.5649\n",
    "Epoch 5/100\n",
    "157/157 [==============================] - 3s 20ms/step - loss: 1.0401 - accuracy: 0.5799 - val_loss: 1.0723 - val_accuracy: 0.5777\n",
    "Epoch 6/100\n",
    "157/157 [==============================] - 3s 20ms/step - loss: 0.9882 - accuracy: 0.5940 - val_loss: 1.0469 - val_accuracy: 0.5836\n",
    "Epoch 7/100\n",
    "157/157 [==============================] - 3s 20ms/step - loss: 0.9528 - accuracy: 0.6046 - val_loss: 1.0102 - val_accuracy: 0.5896\n",
    "Epoch 8/100\n",
    "157/157 [==============================] - 3s 20ms/step - loss: 0.9248 - accuracy: 0.6108 - val_loss: 0.9887 - val_accuracy: 0.6044\n",
    "Epoch 9/100\n",
    "157/157 [==============================] - 3s 20ms/step - loss: 0.8979 - accuracy: 0.6186 - val_loss: 0.9698 - val_accuracy: 0.6062\n",
    "Epoch 10/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.8782 - accuracy: 0.6218 - val_loss: 0.9569 - val_accuracy: 0.6124\n",
    "Epoch 11/100\n",
    "157/157 [==============================] - 3s 20ms/step - loss: 0.8588 - accuracy: 0.6344 - val_loss: 0.9361 - val_accuracy: 0.6222\n",
    "Epoch 12/100\n",
    "157/157 [==============================] - 4s 28ms/step - loss: 0.8433 - accuracy: 0.6418 - val_loss: 0.9260 - val_accuracy: 0.6162\n",
    "Epoch 13/100\n",
    "157/157 [==============================] - 3s 22ms/step - loss: 0.8298 - accuracy: 0.6458 - val_loss: 0.9141 - val_accuracy: 0.6296\n",
    "Epoch 14/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.8172 - accuracy: 0.6510 - val_loss: 0.9010 - val_accuracy: 0.6368\n",
    "Epoch 15/100\n",
    "157/157 [==============================] - 3s 20ms/step - loss: 0.8041 - accuracy: 0.6588 - val_loss: 0.8941 - val_accuracy: 0.6378\n",
    "Epoch 16/100\n",
    "157/157 [==============================] - 3s 20ms/step - loss: 0.7927 - accuracy: 0.6662 - val_loss: 0.8805 - val_accuracy: 0.6414\n",
    "Epoch 17/100\n",
    "157/157 [==============================] - 3s 20ms/step - loss: 0.7826 - accuracy: 0.6742 - val_loss: 0.8738 - val_accuracy: 0.6504\n",
    "Epoch 18/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.7733 - accuracy: 0.6742 - val_loss: 0.8668 - val_accuracy: 0.6546\n",
    "Epoch 19/100\n",
    "157/157 [==============================] - 4s 22ms/step - loss: 0.7628 - accuracy: 0.6858 - val_loss: 0.8605 - val_accuracy: 0.6526\n",
    "Epoch 20/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.7554 - accuracy: 0.6834 - val_loss: 0.8546 - val_accuracy: 0.6580\n",
    "Epoch 21/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.7479 - accuracy: 0.6878 - val_loss: 0.8448 - val_accuracy: 0.6602\n",
    "Epoch 22/100\n",
    "157/157 [==============================] - 3s 22ms/step - loss: 0.7389 - accuracy: 0.6934 - val_loss: 0.8446 - val_accuracy: 0.6636\n",
    "Epoch 23/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.7320 - accuracy: 0.6970 - val_loss: 0.8405 - val_accuracy: 0.6688\n",
    "Epoch 24/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.7248 - accuracy: 0.7016 - val_loss: 0.8316 - val_accuracy: 0.6662\n",
    "Epoch 25/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.7174 - accuracy: 0.7012 - val_loss: 0.8309 - val_accuracy: 0.6694\n",
    "Epoch 26/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.7094 - accuracy: 0.7136 - val_loss: 0.8464 - val_accuracy: 0.6570\n",
    "Epoch 27/100\n",
    "157/157 [==============================] - 3s 22ms/step - loss: 0.7048 - accuracy: 0.7094 - val_loss: 0.8236 - val_accuracy: 0.6718\n",
    "Epoch 28/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.6972 - accuracy: 0.7166 - val_loss: 0.8181 - val_accuracy: 0.6744\n",
    "Epoch 29/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.6905 - accuracy: 0.7228 - val_loss: 0.8137 - val_accuracy: 0.6758\n",
    "Epoch 30/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.6852 - accuracy: 0.7260 - val_loss: 0.8153 - val_accuracy: 0.6838\n",
    "Epoch 31/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.6767 - accuracy: 0.7328 - val_loss: 0.8102 - val_accuracy: 0.6808\n",
    "Epoch 32/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.6718 - accuracy: 0.7306 - val_loss: 0.8088 - val_accuracy: 0.6758\n",
    "Epoch 33/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.6634 - accuracy: 0.7364 - val_loss: 0.8070 - val_accuracy: 0.6786\n",
    "Epoch 34/100\n",
    "157/157 [==============================] - 3s 22ms/step - loss: 0.6601 - accuracy: 0.7380 - val_loss: 0.8019 - val_accuracy: 0.6886\n",
    "Epoch 35/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.6527 - accuracy: 0.7454 - val_loss: 0.7990 - val_accuracy: 0.6862\n",
    "Epoch 36/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.6472 - accuracy: 0.7436 - val_loss: 0.8035 - val_accuracy: 0.6852\n",
    "Epoch 37/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.6422 - accuracy: 0.7452 - val_loss: 0.7966 - val_accuracy: 0.6880\n",
    "Epoch 38/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.6361 - accuracy: 0.7490 - val_loss: 0.7959 - val_accuracy: 0.6920\n",
    "Epoch 39/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.6323 - accuracy: 0.7521 - val_loss: 0.7938 - val_accuracy: 0.6890\n",
    "Epoch 40/100\n",
    "157/157 [==============================] - 3s 22ms/step - loss: 0.6271 - accuracy: 0.7537 - val_loss: 0.7958 - val_accuracy: 0.6956\n",
    "Epoch 41/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.6229 - accuracy: 0.7589 - val_loss: 0.7945 - val_accuracy: 0.6942\n",
    "Epoch 42/100\n",
    "157/157 [==============================] - 4s 23ms/step - loss: 0.6167 - accuracy: 0.7665 - val_loss: 0.7885 - val_accuracy: 0.6988\n",
    "Epoch 43/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.6127 - accuracy: 0.7597 - val_loss: 0.7881 - val_accuracy: 0.7022\n",
    "Epoch 44/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.6072 - accuracy: 0.7613 - val_loss: 0.7884 - val_accuracy: 0.6932\n",
    "Epoch 45/100\n",
    "157/157 [==============================] - 3s 22ms/step - loss: 0.6031 - accuracy: 0.7675 - val_loss: 0.7815 - val_accuracy: 0.7014\n",
    "Epoch 46/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.5997 - accuracy: 0.7681 - val_loss: 0.7854 - val_accuracy: 0.6936\n",
    "Epoch 47/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.5947 - accuracy: 0.7725 - val_loss: 0.7844 - val_accuracy: 0.7072\n",
    "Epoch 48/100\n",
    "157/157 [==============================] - 4s 26ms/step - loss: 0.5901 - accuracy: 0.7711 - val_loss: 0.7799 - val_accuracy: 0.7050\n",
    "Epoch 49/100\n",
    "157/157 [==============================] - 3s 22ms/step - loss: 0.5870 - accuracy: 0.7743 - val_loss: 0.7791 - val_accuracy: 0.7004\n",
    "Epoch 50/100\n",
    "157/157 [==============================] - 3s 22ms/step - loss: 0.5830 - accuracy: 0.7777 - val_loss: 0.7861 - val_accuracy: 0.7070\n",
    "Epoch 51/100\n",
    "157/157 [==============================] - 4s 24ms/step - loss: 0.5780 - accuracy: 0.7737 - val_loss: 0.7851 - val_accuracy: 0.7048\n",
    "Epoch 52/100\n",
    "157/157 [==============================] - 4s 23ms/step - loss: 0.5758 - accuracy: 0.7747 - val_loss: 0.7738 - val_accuracy: 0.7114\n",
    "Epoch 53/100\n",
    "157/157 [==============================] - 4s 23ms/step - loss: 0.5698 - accuracy: 0.7813 - val_loss: 0.7688 - val_accuracy: 0.7124\n",
    "Epoch 54/100\n",
    "157/157 [==============================] - 4s 23ms/step - loss: 0.5666 - accuracy: 0.7803 - val_loss: 0.7673 - val_accuracy: 0.7134\n",
    "Epoch 55/100\n",
    "157/157 [==============================] - 4s 24ms/step - loss: 0.5643 - accuracy: 0.7827 - val_loss: 0.7679 - val_accuracy: 0.7124\n",
    "Epoch 56/100\n",
    "157/157 [==============================] - 4s 27ms/step - loss: 0.5605 - accuracy: 0.7851 - val_loss: 0.7745 - val_accuracy: 0.7084\n",
    "Epoch 57/100\n",
    "157/157 [==============================] - 4s 26ms/step - loss: 0.5583 - accuracy: 0.7855 - val_loss: 0.7714 - val_accuracy: 0.7100\n",
    "Epoch 58/100\n",
    "157/157 [==============================] - 4s 26ms/step - loss: 0.5536 - accuracy: 0.7859 - val_loss: 0.7654 - val_accuracy: 0.7176\n",
    "Epoch 59/100\n",
    "157/157 [==============================] - 4s 23ms/step - loss: 0.5505 - accuracy: 0.7893 - val_loss: 0.7597 - val_accuracy: 0.7128\n",
    "Epoch 60/100\n",
    "157/157 [==============================] - 4s 23ms/step - loss: 0.5459 - accuracy: 0.7895 - val_loss: 0.7695 - val_accuracy: 0.7120\n",
    "Epoch 61/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.5442 - accuracy: 0.7893 - val_loss: 0.7615 - val_accuracy: 0.7188\n",
    "Epoch 62/100\n",
    "157/157 [==============================] - 4s 23ms/step - loss: 0.5410 - accuracy: 0.7969 - val_loss: 0.7627 - val_accuracy: 0.7166\n",
    "Epoch 63/100\n",
    "157/157 [==============================] - 4s 22ms/step - loss: 0.5373 - accuracy: 0.7967 - val_loss: 0.7600 - val_accuracy: 0.7168\n",
    "Epoch 64/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.5347 - accuracy: 0.7993 - val_loss: 0.7616 - val_accuracy: 0.7226\n",
    "Epoch 65/100\n",
    "157/157 [==============================] - 3s 22ms/step - loss: 0.5320 - accuracy: 0.7973 - val_loss: 0.7632 - val_accuracy: 0.7130\n",
    "Epoch 66/100\n",
    "157/157 [==============================] - 3s 22ms/step - loss: 0.5287 - accuracy: 0.8005 - val_loss: 0.7677 - val_accuracy: 0.7244\n",
    "Epoch 67/100\n",
    "157/157 [==============================] - 3s 22ms/step - loss: 0.5277 - accuracy: 0.8037 - val_loss: 0.7541 - val_accuracy: 0.7158\n",
    "Epoch 68/100\n",
    "157/157 [==============================] - 4s 23ms/step - loss: 0.5242 - accuracy: 0.8005 - val_loss: 0.7640 - val_accuracy: 0.7188\n",
    "Epoch 69/100\n",
    "157/157 [==============================] - 4s 24ms/step - loss: 0.5211 - accuracy: 0.8005 - val_loss: 0.7580 - val_accuracy: 0.7252\n",
    "Epoch 70/100\n",
    "157/157 [==============================] - 4s 23ms/step - loss: 0.5194 - accuracy: 0.7997 - val_loss: 0.7571 - val_accuracy: 0.7218\n",
    "Epoch 71/100\n",
    "157/157 [==============================] - 4s 22ms/step - loss: 0.5174 - accuracy: 0.8031 - val_loss: 0.7534 - val_accuracy: 0.7188\n",
    "Epoch 72/100\n",
    "157/157 [==============================] - 3s 21ms/step - loss: 0.5148 - accuracy: 0.8049 - val_loss: 0.7503 - val_accuracy: 0.7256\n",
    "Epoch 73/100\n",
    "157/157 [==============================] - 3s 22ms/step - loss: 0.5114 - accuracy: 0.8023 - val_loss: 0.7513 - val_accuracy: 0.7232\n",
    "Epoch 74/100\n",
    "157/157 [==============================] - 3s 22ms/step - loss: 0.5112 - accuracy: 0.8051 - val_loss: 0.7549 - val_accuracy: 0.7242\n",
    "Epoch 75/100\n",
    "157/157 [==============================] - 4s 22ms/step - loss: 0.5079 - accuracy: 0.8107 - val_loss: 0.7537 - val_accuracy: 0.7268\n",
    "Epoch 76/100\n",
    "157/157 [==============================] - 4s 26ms/step - loss: 0.5046 - accuracy: 0.8087 - val_loss: 0.7533 - val_accuracy: 0.7294\n",
    "Epoch 77/100\n",
    "157/157 [==============================] - 4s 24ms/step - loss: 0.5030 - accuracy: 0.8121 - val_loss: 0.7487 - val_accuracy: 0.7332\n",
    "Epoch 78/100\n",
    "157/157 [==============================] - 4s 27ms/step - loss: 0.5014 - accuracy: 0.8099 - val_loss: 0.7593 - val_accuracy: 0.7242\n",
    "Epoch 79/100\n",
    "157/157 [==============================] - 4s 26ms/step - loss: 0.4996 - accuracy: 0.8095 - val_loss: 0.7559 - val_accuracy: 0.7248\n",
    "Epoch 80/100\n",
    "157/157 [==============================] - 4s 25ms/step - loss: 0.4956 - accuracy: 0.8127 - val_loss: 0.7484 - val_accuracy: 0.7248\n",
    "Epoch 81/100\n",
    "157/157 [==============================] - 4s 23ms/step - loss: 0.4951 - accuracy: 0.8119 - val_loss: 0.7566 - val_accuracy: 0.7358\n",
    "Epoch 82/100\n",
    "157/157 [==============================] - 4s 23ms/step - loss: 0.4921 - accuracy: 0.8135 - val_loss: 0.7643 - val_accuracy: 0.7292\n",
    "Epoch 83/100\n",
    "157/157 [==============================] - 4s 23ms/step - loss: 0.4903 - accuracy: 0.8149 - val_loss: 0.7533 - val_accuracy: 0.7306\n",
    "Epoch 84/100\n",
    "157/157 [==============================] - 4s 25ms/step - loss: 0.4884 - accuracy: 0.8113 - val_loss: 0.7659 - val_accuracy: 0.7332\n",
    "Epoch 85/100\n",
    "157/157 [==============================] - 4s 23ms/step - loss: 0.4861 - accuracy: 0.8159 - val_loss: 0.7578 - val_accuracy: 0.7294\n",
    "Epoch 86/100\n",
    "157/157 [==============================] - 4s 26ms/step - loss: 0.4852 - accuracy: 0.8123 - val_loss: 0.7593 - val_accuracy: 0.7264\n",
    "Epoch 87/100\n",
    "157/157 [==============================] - 4s 24ms/step - loss: 0.4823 - accuracy: 0.8199 - val_loss: 0.7521 - val_accuracy: 0.7306\n",
    "Epoch 88/100\n",
    "157/157 [==============================] - 4s 23ms/step - loss: 0.4819 - accuracy: 0.8179 - val_loss: 0.7534 - val_accuracy: 0.7346\n",
    "Epoch 89/100\n",
    "157/157 [==============================] - 4s 24ms/step - loss: 0.4823 - accuracy: 0.8133 - val_loss: 0.7560 - val_accuracy: 0.7354\n",
    "Epoch 90/100\n",
    "157/157 [==============================] - 4s 23ms/step - loss: 0.4783 - accuracy: 0.8163 - val_loss: 0.7630 - val_accuracy: 0.7318\n",
    "Epoch 91/100\n",
    "157/157 [==============================] - 4s 23ms/step - loss: 0.4772 - accuracy: 0.8195 - val_loss: 0.7750 - val_accuracy: 0.7356\n",
    "Epoch 92/100\n",
    "157/157 [==============================] - 4s 24ms/step - loss: 0.4762 - accuracy: 0.8213 - val_loss: 0.7547 - val_accuracy: 0.7332\n",
    "Epoch 93/100\n",
    "157/157 [==============================] - 4s 25ms/step - loss: 0.4731 - accuracy: 0.8241 - val_loss: 0.7652 - val_accuracy: 0.7358\n",
    "Epoch 94/100\n",
    "157/157 [==============================] - 4s 22ms/step - loss: 0.4710 - accuracy: 0.8217 - val_loss: 0.7653 - val_accuracy: 0.7292\n",
    "Epoch 95/100\n",
    "157/157 [==============================] - 4s 23ms/step - loss: 0.4719 - accuracy: 0.8165 - val_loss: 0.7507 - val_accuracy: 0.7342\n",
    "Epoch 96/100\n",
    "157/157 [==============================] - 4s 22ms/step - loss: 0.4699 - accuracy: 0.8201 - val_loss: 0.7677 - val_accuracy: 0.7320\n",
    "Epoch 97/100\n",
    "157/157 [==============================] - 3s 22ms/step - loss: 0.4682 - accuracy: 0.8211 - val_loss: 0.7661 - val_accuracy: 0.7386\n",
    "Epoch 98/100\n",
    "157/157 [==============================] - 4s 22ms/step - loss: 0.4674 - accuracy: 0.8231 - val_loss: 0.7651 - val_accuracy: 0.7372\n",
    "Epoch 99/100\n",
    "157/157 [==============================] - 4s 23ms/step - loss: 0.4668 - accuracy: 0.8185 - val_loss: 0.7609 - val_accuracy: 0.7320\n",
    "Epoch 100/100\n",
    "157/157 [==============================] - 4s 25ms/step - loss: 0.4653 - accuracy: 0.8215 - val_loss: 0.7573 - val_accuracy: 0.7344\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# plt.plot(history.history['accuracy'], label='Training Accuracy')\u001b[39;00m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43ml\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# plt.ylim(0.2, 0.6)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'l' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "# plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.plot(l, label='Validation Accuracy')\n",
    "# plt.ylim(0.2, 0.6)\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4880"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediapipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
